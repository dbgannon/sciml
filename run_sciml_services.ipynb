{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook can be used to run and test the sciml services\n",
    "It load the configuration files and all the output of the main topic classifications.\n",
    "Once you have started the services you can send a message to configure one of the classifiers to wait on a topic\n",
    "queue and then send it some items to classify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pika\n",
    "import time\n",
    "import azure\n",
    "#from azure.storage.table import TableService\n",
    "#from azure.storage.blob import BlobService\n",
    "import pickle\n",
    "import random\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "def read_config_from_azure_blob(subj):\n",
    "    base = \"http://esciencegroup.blob.core.windows.net/scimlpublic\"\n",
    "    docpath =base+ \"/config_\"+subj+\".json\"\n",
    "    f = urllib.urlopen(docpath)\n",
    "    doc = f.read()\n",
    "    z =json.loads(doc)\n",
    "    subject = z['subject']\n",
    "    loadset = z['loadset']\n",
    "    subtopics = []\n",
    "    for w in z['supertopics']:\n",
    "        subtopics.extend([(w[0], w[1])])\n",
    "    return subject, loadset, subtopics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load all the output of the main topic classifiers.\n",
    "these have been stored in files named \"dump_subject_subtopic_name.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Physics', u'math', u'bio', u'compsci', u'finance']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subject, loadset,supertopics =read_config_from_azure_blob(\"all4\")\n",
    "basepath = \"http://esciencegroup.blob.core.windows.net/scimlpublic\"\n",
    "namspath = basepath+\"/supertopic_names-\"+subject+\".p\"\n",
    "groupb = urllib.urlopen(namspath).read()   \n",
    "groupnames = pickle.loads(str(groupb))\n",
    "print groupnames\n",
    "listTable = {gname:[] for gname in groupnames}\n",
    "for nam in groupnames:      \n",
    "    path = basepath+\"/dump_\"+subject+\"_subtopic_\"+nam+\".p\"\n",
    "    bys = urllib.urlopen(path).read()\n",
    "    listTable[nam] = pickle.loads(str(bys))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics 2988\n",
      "math 1943\n",
      "bio 817\n",
      "compsci 1626\n",
      "finance 453\n"
     ]
    }
   ],
   "source": [
    "for nam in groupnames:\n",
    "    print nam + \" \"+ str(len(listTable[nam]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'math', u'compsci', '??', 'A double nanohole in a metal film was used to trap nanoparticles (20 nm diameter) and simultaneously record their Raman spectrum using the trapping laser as the excitation source. This allowed for the identification of characteristic Stokes lines for titania and polystyrene nanoparticles, showing the capability for material identification of nanoparticles once trapped. Increased Raman signal is observed for the trapping of multiple nanoparticles. This system combines the benefits of nanoparticle isolation and manipulation with unique identification.', u'Physics', u'Raman Spectroscopy of Single Nanoparticles in a Double-Nanohole Optical   Tweezer System [physics.optics]')\n"
     ]
    }
   ],
   "source": [
    "print listTable[\"math\"][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each main topic we create a dictionary indexed by the group name.  the entry is a list of the json style object that the classifier services will expect to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jsonitems = {\"Physics\":[], \"bio\":[], \"math\":[], \"compsci\":[], \"finance\":[]}\n",
    "for item in listTable[\"Physics\"]:\n",
    "    jsonitems[\"Physics\"].extend([(\"phy\", {\"rf\": item[0], \"best\": item[1], \"cent\": item[2], \"doc\": item[3], \n",
    "                      \"truetop\": item[4], \"title\": item[5]})])\n",
    "for item in listTable[\"bio\"]:\n",
    "    jsonitems[\"bio\"].extend([(\"bio\", {\"rf\": item[0], \"best\": item[1], \"cent\": item[2], \"doc\": item[3], \n",
    "                     \"truetop\": item[4], \"title\": item[5]})])\n",
    "for item in listTable[\"math\"]:\n",
    "    jsonitems[\"math\"].extend([(\"math\",{\"rf\": item[0], \"best\": item[1], \"cent\": item[2], \"doc\": item[3], \n",
    "                      \"truetop\": item[4], \"title\": item[5]})])\n",
    "for item in listTable[\"compsci\"]:\n",
    "    jsonitems[\"compsci\"].extend([(\"compsci\",{\"rf\": item[0], \"best\": item[1], \"cent\": item[2], \"doc\": item[3], \n",
    "                      \"truetop\": item[4], \"title\": item[5]})])\n",
    "for item in listTable[\"finance\"]:\n",
    "    jsonitems[\"finance\"].extend([(\"finance\",{\"rf\": item[0], \"best\": item[1], \"cent\": item[2], \"doc\": item[3], \n",
    "                      \"truetop\": item[4], \"title\": item[5]})])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the names of the queues we need to have in the message broker are as follows.\n",
    "You will notice we have a disconnect with the name for Physics.   it's queue is phy.  sorry\n",
    "for this inconsistancy.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queueset = set([\"math\", \"bio\", \"phy\", \"finance\", \"compsci\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "creds = pika.PlainCredentials('dbg', 'dbgrabbit')\n",
    "rabbitmq_location = \"dbgswarm1.cloudapp.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sendtopic(topic):\n",
    "    connec = pika.BlockingConnection(pika.ConnectionParameters(rabbitmq_location, 5672,'/',creds))\n",
    "    chan = connec.channel()\n",
    "    chan.queue_declare(queue=\"roles\")\n",
    "    chan.basic_publish(exchange='',\n",
    "        routing_key=\"roles\",\n",
    "        body=topic)  \n",
    "    connec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sendreset(topic):\n",
    "    connec = pika.BlockingConnection(pika.ConnectionParameters(rabbitmq_location, 5672,'/',creds))\n",
    "    chan = connec.channel()\n",
    "    chan.queue_declare(queue=topic)\n",
    "    chan.basic_publish(exchange='',\n",
    "        routing_key=topic,\n",
    "        body=\"reset\")\n",
    "    connec.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to tell a classifier to start listening on a topic do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sendtopic(\"bio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if a classifier is already listening on a topic and you want it to stop do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sendreset(\"bio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this can be used to send a set of items from the main classification into the various queues for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending json to pipe =bio\n",
      "sending json to pipe =bio\n",
      "sending json to pipe =bio\n"
     ]
    }
   ],
   "source": [
    "connec = pika.BlockingConnection(pika.ConnectionParameters(rabbitmq_location, 5672,'/',creds))\n",
    "chan = connec.channel()\n",
    "#for nam in groupnames:\n",
    "for nam in [\"bio\"]: #,\"math\", \"compsci\",\"finance\", \"Physics\"]: \n",
    "    for x in jsonitems[nam][201:204]:\n",
    "        print \"sending json to pipe =\"+x[0]\n",
    "        z = x[1]\n",
    "        doc = z[\"doc\"]\n",
    "        doc = doc.replace(\"\\\\\", \"\")\n",
    "        doc = doc.replace(\"'\",\"\")\n",
    "        doc = doc.replace(\"\\'\",\"\")\n",
    "        doc = doc.replace('\"',\"\")\n",
    "        x[1][\"doc\"]= doc\n",
    "        y = str(x[1])\n",
    "        y=y.replace(\"u'\",\"'\")\n",
    "        y=y.replace(\"'\",'\"')\n",
    "        chan.basic_publish(exchange='',\n",
    "            routing_key=x[0],\n",
    "            body=str(y))\n",
    "            #print \" sent startup: \"+str(y)\n",
    "        time.sleep(0.1)\n",
    "connec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sendreset(\"bio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
